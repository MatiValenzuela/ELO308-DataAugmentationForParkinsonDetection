{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPh2KVwkqrnraXvcvL3nIvD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatiValenzuela/ELO308-DataAugmentationForParkinsonDetection/blob/main/DataAugmentation_mix_Tecnicas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bibliotecas"
      ],
      "metadata": {
        "id": "d59Kc72PvN6I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GEHmK8DUb-vV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "import torchaudio\n",
        "import torchaudio.functional as F\n",
        "import torchaudio.transforms as T\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import KFold\n",
        "import seaborn as sn\n",
        "import sklearn\n",
        "from sklearn.manifold import TSNE\n",
        "from imblearn.metrics import sensitivity_specificity_support"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "audio_data_path = '/content/drive/MyDrive/Memoria/Pataka'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArQB729lcX0y",
        "outputId": "260e57af-212b-4be0-e0ad-03c844e0f523"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga de datos\n",
        "En primer lugar se genera un dataframe que incluye el path a los distintos archivos de audio, un ID y un tag siendo 'PD' = 1 y 'HC' = 0"
      ],
      "metadata": {
        "id": "H4CoPzXFjfzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH_Gita = '/content/drive/MyDrive/Memoria/Pataka'\n",
        "\n",
        "SAMPLE_RATE = 44100\n",
        "#AVPEPUDEAC0001_pataka.wav   -> Formato de los archivos\n",
        "data_Gita = pd.DataFrame(columns=['Speaker_ID', 'Label', 'Path'])\n",
        "Speaker_PD=0\n",
        "Speaker_HC=50 #Sabemos que son 50 muestras por cada uno.\n",
        "\n",
        "for dirname, _, filenames in os.walk(DATA_PATH_Gita):\n",
        "\n",
        "    for filename in filenames:\n",
        "        file_path = os.path.join(dirname, filename)\n",
        "\n",
        "        if dirname.find('PD')!=-1:\n",
        "            Speaker_PD+=1\n",
        "            Speaker_ID=Speaker_PD\n",
        "            Label=1\n",
        "        else:\n",
        "            Speaker_HC+=1\n",
        "            Speaker_ID=Speaker_HC\n",
        "            Label=0\n",
        "\n",
        "\n",
        "        data_Gita=pd.concat([data_Gita, pd.DataFrame({\"Speaker_ID\": [Speaker_ID],\n",
        "                            \"Label\": [Label],\n",
        "                            \"Path\": [file_path]\n",
        "                             })],ignore_index=True)\n",
        "print(\"number of files is {}\".format(len(data_Gita)))\n",
        "data_Gita.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EeBHQljldm3k",
        "outputId": "b6fa6bad-d8d7-4718-d885-6e4f19452eb2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of files is 100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Speaker_ID Label                                               Path\n",
              "0          1     1  /content/drive/MyDrive/Memoria/Pataka/PD/AVPEP...\n",
              "1          2     1  /content/drive/MyDrive/Memoria/Pataka/PD/AVPEP...\n",
              "2          3     1  /content/drive/MyDrive/Memoria/Pataka/PD/AVPEP...\n",
              "3          4     1  /content/drive/MyDrive/Memoria/Pataka/PD/AVPEP...\n",
              "4          5     1  /content/drive/MyDrive/Memoria/Pataka/PD/AVPEP..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a4b3408-cddc-4c24-a5ac-57b633082e86\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Speaker_ID</th>\n",
              "      <th>Label</th>\n",
              "      <th>Path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>/content/drive/MyDrive/Memoria/Pataka/PD/AVPEP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>/content/drive/MyDrive/Memoria/Pataka/PD/AVPEP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>/content/drive/MyDrive/Memoria/Pataka/PD/AVPEP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>/content/drive/MyDrive/Memoria/Pataka/PD/AVPEP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>/content/drive/MyDrive/Memoria/Pataka/PD/AVPEP...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a4b3408-cddc-4c24-a5ac-57b633082e86')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1a4b3408-cddc-4c24-a5ac-57b633082e86 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1a4b3408-cddc-4c24-a5ac-57b633082e86');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ea0423d8-e628-4d85-8a69-ef8d855348f2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea0423d8-e628-4d85-8a69-ef8d855348f2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ea0423d8-e628-4d85-8a69-ef8d855348f2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_Gita",
              "summary": "{\n  \"name\": \"data_Gita\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"Speaker_ID\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 1,\n        \"max\": 100,\n        \"samples\": [\n          84,\n          54,\n          71\n        ],\n        \"num_unique_values\": 100,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 1,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"/content/drive/MyDrive/Memoria/Pataka/HC/AVPEPUDEAC0047_pataka.wav\",\n          \"/content/drive/MyDrive/Memoria/Pataka/HC/AVPEPUDEAC0005_pataka.wav\"\n        ],\n        \"num_unique_values\": 100,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Data Gita')\n",
        "print('Parkinson')\n",
        "PD_Gita=data_Gita[data_Gita['Label']==1].sort_values(by=['Speaker_ID'])['Speaker_ID'].unique()\n",
        "print(PD_Gita)\n",
        "print('size=', PD_Gita.shape)\n",
        "print('Control')\n",
        "HC_Gita=data_Gita[data_Gita['Label']==0].sort_values(by=['Speaker_ID'])['Speaker_ID'].unique()\n",
        "print(HC_Gita)\n",
        "print('size=', HC_Gita.shape)\n",
        "\n",
        "#Partition Gita\n",
        "Train_Subject_Gita=np.concatenate([PD_Gita, HC_Gita])\n",
        "print(\"Data Gita\")\n",
        "print(\"To train:\",np.unique(Train_Subject_Gita).shape)\n",
        "data_train_Gita=data_Gita"
      ],
      "metadata": {
        "id": "scf_WlWinINZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e21eb6a-c1ac-4ba7-9542-511947d62a1a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Gita\n",
            "Parkinson\n",
            "[1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27\n",
            " 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50]\n",
            "size= (50,)\n",
            "Control\n",
            "[51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n",
            " 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98\n",
            " 99 100]\n",
            "size= (50,)\n",
            "Data Gita\n",
            "To train: (100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga de datos Neurovoz"
      ],
      "metadata": {
        "id": "UwV0nkjGzSa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH_NeuroV = '/content/drive/MyDrive/Memoria/Neurovoz/PATAKA'\n",
        "\n",
        "SAMPLE_RATE_NeuroV = 44100\n",
        "data_NeuroV = pd.DataFrame(columns=['Speaker_ID', 'Label', 'Path'])\n",
        "for dirname, _, filenames in os.walk(DATA_PATH_NeuroV):\n",
        "    for filename in filenames:\n",
        "            file_path = os.path.join(dirname, filename)\n",
        "            if filename.find('wav')!=-1:\n",
        "                identifiers=filename.split('.')[0].split('_')\n",
        "                Speaker_ID=int(identifiers[2])+100\n",
        "                if identifiers[0]=='PD':\n",
        "                    Label=1\n",
        "                else:\n",
        "                    Label=0\n",
        "            data_NeuroV=pd.concat([data_NeuroV, pd.DataFrame({\"Speaker_ID\": [Speaker_ID],\n",
        "                            \"Label\": [Label],\n",
        "                            \"Path\": [file_path]\n",
        "                             })],ignore_index=True)\n",
        "print(\"number of files is {}\".format(len(data_NeuroV)))\n",
        "data_NeuroV.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "XuM1N4zkzWud",
        "outputId": "8583baa0-ff49-4df4-dd4d-a4dd91bc1209"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of files is 86\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Speaker_ID Label                                               Path\n",
              "0        134     0  /content/drive/MyDrive/Memoria/Neurovoz/PATAKA...\n",
              "1        160     0  /content/drive/MyDrive/Memoria/Neurovoz/PATAKA...\n",
              "2        149     0  /content/drive/MyDrive/Memoria/Neurovoz/PATAKA...\n",
              "3        153     0  /content/drive/MyDrive/Memoria/Neurovoz/PATAKA...\n",
              "4        136     0  /content/drive/MyDrive/Memoria/Neurovoz/PATAKA..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f899fd0-677d-4880-85da-2efd87bc1f89\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Speaker_ID</th>\n",
              "      <th>Label</th>\n",
              "      <th>Path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>134</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/drive/MyDrive/Memoria/Neurovoz/PATAKA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>160</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/drive/MyDrive/Memoria/Neurovoz/PATAKA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>149</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/drive/MyDrive/Memoria/Neurovoz/PATAKA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>153</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/drive/MyDrive/Memoria/Neurovoz/PATAKA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>136</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/drive/MyDrive/Memoria/Neurovoz/PATAKA...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f899fd0-677d-4880-85da-2efd87bc1f89')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1f899fd0-677d-4880-85da-2efd87bc1f89 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1f899fd0-677d-4880-85da-2efd87bc1f89');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-204f3c67-7cef-48be-a63c-8d2679a9f5e1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-204f3c67-7cef-48be-a63c-8d2679a9f5e1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-204f3c67-7cef-48be-a63c-8d2679a9f5e1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_NeuroV",
              "summary": "{\n  \"name\": \"data_NeuroV\",\n  \"rows\": 86,\n  \"fields\": [\n    {\n      \"column\": \"Speaker_ID\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 106,\n        \"max\": 245,\n        \"samples\": [\n          146,\n          134,\n          131\n        ],\n        \"num_unique_values\": 86,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 1,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"/content/drive/MyDrive/Memoria/Neurovoz/PATAKA/PD/PD_PATAKA_0046.wav\",\n          \"/content/drive/MyDrive/Memoria/Neurovoz/PATAKA/HC/HC_PATAKA_0034.wav\"\n        ],\n        \"num_unique_values\": 86,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Data NeuroVoz')\n",
        "print('Parkinson')\n",
        "PD_NeuroV=data_NeuroV[data_NeuroV['Label']==1].sort_values(by=['Speaker_ID'])['Speaker_ID'].unique()\n",
        "print(PD_NeuroV)\n",
        "print('size=', PD_NeuroV.shape)\n",
        "print('Control')\n",
        "HC_NeuroV=data_NeuroV[data_NeuroV['Label']==0].sort_values(by=['Speaker_ID'])['Speaker_ID'].unique()\n",
        "print(HC_NeuroV)\n",
        "print('size=', HC_NeuroV.shape)\n",
        "\n",
        "#Partition NeuroVoz\n",
        "Train_Subject_NeuroV=np.concatenate([PD_NeuroV, HC_NeuroV])\n",
        "print(\"Data NeuroVoz\")\n",
        "print(\"To test:\",np.unique(Train_Subject_NeuroV).shape)\n",
        "data_test_NeuroV=data_NeuroV"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JncLOiUkzaXx",
        "outputId": "09ece153-ea50-41bd-ccd5-12a74e1ccdc7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data NeuroVoz\n",
            "Parkinson\n",
            "[106 107 108 109 110 111 112 113 115 116 117 118 119 120 124 125 127 128\n",
            " 129 130 131 132 133 135 137 138 139 140 141 142 143 144 146 147 166 168\n",
            " 169 170 177 209 211 213 215 217]\n",
            "size= (44,)\n",
            "Control\n",
            "[134 136 148 149 151 152 153 154 155 156 160 161 162 163 164 172 174 175\n",
            " 176 181 182 185 186 205 212 216 218 220 222 228 230 231 232 234 236 237\n",
            " 238 240 241 242 243 245]\n",
            "size= (42,)\n",
            "Data NeuroVoz\n",
            "To test: (86,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Procesamiento de los datos\n",
        "Primero segmentamos nuestras señales en base a un umbral"
      ],
      "metadata": {
        "id": "DIp4bb-trPGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#selecting 400ms overlap in 50ms of audio signal example\n",
        "def process_select_signals(data, SAMPLE_RATE, want_to_augment = True, tecnica = 0):#tecnica = 0: Pitch - tecnica = 1: Speed\n",
        "    time_leng=0.4 #Esto son 400 ms.\n",
        "    sample_leng=int(time_leng*SAMPLE_RATE) #Sample_rate = 44100. sample_leng = 0.4*44100 = 17640\n",
        "    overloap=2\n",
        "    signals, y_label, subject_group, tono =[],[],[],[]\n",
        "    data_size = len(data)\n",
        "    total_segments=0\n",
        "    processed_audios = 0\n",
        "\n",
        "    if want_to_augment:\n",
        "      augmentedSignals, augmentedY_label, augmentedSubject_group =[],[],[]\n",
        "      augmented_data_counter = 0\n",
        "      augment_offset = 1000\n",
        "\n",
        "\n",
        "\n",
        "    #Processs data to train\n",
        "    for data_ind, file_path in enumerate(data.Path):\n",
        "        audio, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "\n",
        "        augmented_flag = False\n",
        "\n",
        "        if want_to_augment:\n",
        "          prob_aug = random.random()\n",
        "          if prob_aug <= 1:\n",
        "            #Apply data augmentation\n",
        "            if tecnica == 0:\n",
        "              bins_per_octave = 12\n",
        "              pitch_change = 4 * ((random.random()*2)-1)\n",
        "              augmented_audio = librosa.effects.pitch_shift(audio,sr=sample_rate, n_steps=pitch_change, bins_per_octave=bins_per_octave)\n",
        "            elif tecnica == 1:\n",
        "              speed_rate = random.uniform(0.5,1.6)\n",
        "              augmented_audio = librosa.effects.time_stretch(audio,rate=speed_rate)\n",
        "\n",
        "            data_size += 1 #Now i have one more audio to process\n",
        "            augmented_flag = True\n",
        "            augmented_data_counter += 1\n",
        "\n",
        "          #else: Don't apply data augmentantion\n",
        "\n",
        "        for a in range(2):\n",
        "          if want_to_augment and augmented_flag and a == 1:\n",
        "              audio = augmented_audio\n",
        "              #print(\"Now with the augmented data\")\n",
        "          elif (want_to_augment == False or augmented_flag == False) and a == 1:\n",
        "              break;\n",
        "\n",
        "          audio_len=len(audio)\n",
        "          audio=audio/np.max(abs(audio))\n",
        "          indx=[i for i,x in enumerate(np.sqrt(abs(audio))) if x>.30]\n",
        "\n",
        "          segments=0\n",
        "          if (indx[0]+sample_leng)<audio_len:\n",
        "              for i in range(int((-indx[0]+indx[len(indx)-1])/(sample_leng/overloap))):\n",
        "                  ind_start = i * int(sample_leng/overloap)+indx[0]\n",
        "                  ind_end = ind_start + sample_leng\n",
        "                  if ind_end <= indx[len(indx)-1]:\n",
        "                      signal=np.zeros(sample_leng)\n",
        "                      signal = audio[ind_start:int(ind_end)]\n",
        "\n",
        "                      if want_to_augment and augmented_flag and a == 1:\n",
        "                        augmentedSignals.append(signal)\n",
        "                        augmentedY_label.append(data.iloc[data_ind]['Label'])\n",
        "                        augmentedSubject_group.append(data.iloc[data_ind]['Speaker_ID'] + augment_offset)\n",
        "\n",
        "                      elif a == 0:\n",
        "                        signals.append(signal)\n",
        "                        y_label.append(data.iloc[data_ind]['Label'])\n",
        "                        subject_group.append(data.iloc[data_ind]['Speaker_ID'])\n",
        "\n",
        "                      segments=segments+1\n",
        "              processed_audios += 1\n",
        "              print(\" Processed {}/{} files\".format(processed_audios,data_size),end='')\n",
        "              print(\" Time audio: {} Segments {} \".format((audio_len-1)/sample_rate,segments))\n",
        "          else:\n",
        "              print(\" Processed {}/{} files\".format(processed_audios,data_size),end='')\n",
        "              print(\" Time audio: {} Segments {} \".format((audio_len-1)/sample_rate,0))\n",
        "          total_segments += segments\n",
        "\n",
        "    print(\" Total segments: \", total_segments)\n",
        "\n",
        "    signals = np.stack(signals,axis=0)\n",
        "    y_label = np.stack(y_label,axis=0)\n",
        "    subject_group = np.stack(subject_group,axis=0)\n",
        "\n",
        "    if want_to_augment:\n",
        "      augmentedSignals = np.stack(augmentedSignals,axis=0)\n",
        "      augmentedY_label = np.stack(augmentedY_label,axis=0)\n",
        "      augmentedSubject_group = np.stack(augmentedSubject_group,axis=0)\n",
        "      print(\" Total augmentations: \", augmented_data_counter)\n",
        "      return signals, y_label, subject_group, augmentedSignals, augmentedY_label, augmentedSubject_group\n",
        "\n",
        "    else:\n",
        "      return signals, y_label, subject_group"
      ],
      "metadata": {
        "id": "Dg8Yj4m8Ay8q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data train GITA + Data Augmentation Speed\n",
        "signals_train_Gita, y_label_train_Gita, subject_group_train_Gita, aug_signals_speed, aug_labels_speed, aug_groups_speed = process_select_signals(data_train_Gita, SAMPLE_RATE, tecnica = 1)\n",
        "\n",
        "print(\"-\"*40)\n",
        "# Data train GITA + Data Augmentation Pitch\n",
        "a, b, c, aug_signals_pitch, aug_labels_pitch, aug_groups_pitch = process_select_signals(data_train_Gita, SAMPLE_RATE, tecnica = 0)\n",
        "\n",
        "print(\"-\"*40)\n",
        "# Data test NeuroVoz (sin data augmentation)\n",
        "signals_test_NeuroV, y_label_test_NeuroV, subject_group_test_NeuroV = process_select_signals(data_test_NeuroV, SAMPLE_RATE, want_to_augment = False)"
      ],
      "metadata": {
        "id": "4y5QOsOQpx7E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f477bedb-4e6a-499a-db8d-6aeab9f67297"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Processed 1/101 files Time audio: 3.2960090702947844 Segments 14 \n",
            " Processed 2/101 files Time audio: 3.10421768707483 Segments 13 \n",
            " Processed 2/102 files Time audio: 7.261950113378685 Segments 34 \n",
            " Processed 3/102 files Time audio: 5.305827664399093 Segments 24 \n",
            " Processed 3/103 files Time audio: 6.469138321995465 Segments 30 \n",
            " Processed 4/103 files Time audio: 10.14408163265306 Segments 48 \n",
            " Processed 4/104 files Time audio: 2.5204761904761903 Segments 9 \n",
            " Processed 5/104 files Time audio: 2.802517006802721 Segments 11 \n",
            " Processed 5/105 files Time audio: 7.466031746031746 Segments 35 \n",
            " Processed 6/105 files Time audio: 14.156984126984128 Segments 68 \n",
            " Processed 6/106 files Time audio: 6.533945578231292 Segments 30 \n",
            " Processed 7/106 files Time audio: 4.287596371882086 Segments 19 \n",
            " Processed 7/107 files Time audio: 4.915079365079365 Segments 22 \n",
            " Processed 8/107 files Time audio: 3.399637188208617 Segments 14 \n",
            " Processed 8/108 files Time audio: 4.467210884353742 Segments 20 \n",
            " Processed 9/108 files Time audio: 7.065555555555555 Segments 31 \n",
            " Processed 9/109 files Time audio: 3.5493650793650793 Segments 15 \n",
            " Processed 10/109 files Time audio: 4.488004535147392 Segments 19 \n",
            " Processed 10/110 files Time audio: 10.52297052154195 Segments 50 \n",
            " Processed 11/110 files Time audio: 8.490340136054423 Segments 40 \n",
            " Processed 11/111 files Time audio: 2.988231292517007 Segments 13 \n",
            " Processed 12/111 files Time audio: 2.0322902494331068 Segments 8 \n",
            " Processed 12/112 files Time audio: 4.17984126984127 Segments 19 \n",
            " Processed 13/112 files Time audio: 6.827414965986395 Segments 32 \n",
            " Processed 13/113 files Time audio: 3.1898412698412697 Segments 14 \n",
            " Processed 14/113 files Time audio: 4.279251700680272 Segments 19 \n",
            " Processed 14/114 files Time audio: 6.068208616780045 Segments 28 \n",
            " Processed 15/114 files Time audio: 6.934489795918368 Segments 32 \n",
            " Processed 15/115 files Time audio: 6.781859410430839 Segments 32 \n",
            " Processed 16/115 files Time audio: 11.297392290249434 Segments 53 \n",
            " Processed 16/116 files Time audio: 5.463877551020408 Segments 25 \n",
            " Processed 17/116 files Time audio: 5.82968253968254 Segments 26 \n",
            " Processed 17/117 files Time audio: 6.576893424036281 Segments 30 \n",
            " Processed 18/117 files Time audio: 8.082448979591836 Segments 37 \n",
            " Processed 18/118 files Time audio: 3.325034013605442 Segments 14 \n",
            " Processed 19/118 files Time audio: 4.876190476190477 Segments 23 \n",
            " Processed 19/119 files Time audio: 3.6186394557823127 Segments 16 \n",
            " Processed 20/119 files Time audio: 2.7304988662131517 Segments 11 \n",
            " Processed 20/120 files Time audio: 1.7343990929705215 Segments 7 \n",
            " Processed 21/120 files Time audio: 1.9011564625850341 Segments 8 \n",
            " Processed 21/121 files Time audio: 5.866780045351474 Segments 27 \n",
            " Processed 22/121 files Time audio: 4.711292517006803 Segments 21 \n",
            " Processed 22/122 files Time audio: 3.281859410430839 Segments 14 \n",
            " Processed 23/122 files Time audio: 2.9572562358276646 Segments 13 \n",
            " Processed 23/123 files Time audio: 5.842403628117914 Segments 26 \n",
            " Processed 24/123 files Time audio: 11.229773242630385 Segments 51 \n",
            " Processed 24/124 files Time audio: 4.345238095238095 Segments 18 \n",
            " Processed 25/124 files Time audio: 2.735668934240363 Segments 11 \n",
            " Processed 25/125 files Time audio: 1.4207709750566893 Segments 5 \n",
            " Processed 26/125 files Time audio: 0.9746031746031746 Segments 3 \n",
            " Processed 26/126 files Time audio: 2.1656916099773245 Segments 9 \n",
            " Processed 27/126 files Time audio: 1.8619274376417234 Segments 7 \n",
            " Processed 27/127 files Time audio: 2.364512471655329 Segments 10 \n",
            " Processed 28/127 files Time audio: 2.592199546485261 Segments 11 \n",
            " Processed 28/128 files Time audio: 3.318934240362812 Segments 15 \n",
            " Processed 29/128 files Time audio: 4.447551020408163 Segments 20 \n",
            " Processed 29/129 files Time audio: 2.5707482993197277 Segments 11 \n",
            " Processed 30/129 files Time audio: 1.747687074829932 Segments 7 \n",
            " Processed 30/130 files Time audio: 3.713219954648526 Segments 16 \n",
            " Processed 31/130 files Time audio: 6.602517006802721 Segments 30 \n",
            " Processed 31/131 files Time audio: 6.52859410430839 Segments 30 \n",
            " Processed 32/131 files Time audio: 8.889002267573696 Segments 42 \n",
            " Processed 32/132 files Time audio: 4.131632653061224 Segments 19 \n",
            " Processed 33/132 files Time audio: 4.151496598639456 Segments 19 \n",
            " Processed 33/133 files Time audio: 4.568458049886622 Segments 20 \n",
            " Processed 34/133 files Time audio: 4.610680272108843 Segments 20 \n",
            " Processed 34/134 files Time audio: 6.379342403628118 Segments 30 \n",
            " Processed 35/134 files Time audio: 4.0 Segments 18 \n",
            " Processed 35/135 files Time audio: 3.768140589569161 Segments 16 \n",
            " Processed 36/135 files Time audio: 2.3848526077097505 Segments 10 \n",
            " Processed 36/136 files Time audio: 1.9452380952380952 Segments 7 \n",
            " Processed 37/136 files Time audio: 1.3583219954648527 Segments 4 \n",
            " Processed 37/137 files Time audio: 3.4593197278911565 Segments 15 \n",
            " Processed 38/137 files Time audio: 6.11421768707483 Segments 27 \n",
            " Processed 38/138 files Time audio: 7.7713378684807255 Segments 36 \n",
            " Processed 39/138 files Time audio: 7.831587301587302 Segments 36 \n",
            " Processed 39/139 files Time audio: 1.3895238095238096 Segments 5 \n",
            " Processed 40/139 files Time audio: 1.3073242630385487 Segments 5 \n",
            " Processed 40/140 files Time audio: 6.407369614512471 Segments 30 \n",
            " Processed 41/140 files Time audio: 5.680090702947846 Segments 26 \n",
            " Processed 41/141 files Time audio: 5.553083900226757 Segments 25 \n",
            " Processed 42/141 files Time audio: 3.9056689342403628 Segments 17 \n",
            " Processed 42/142 files Time audio: 6.140181405895691 Segments 28 \n",
            " Processed 43/142 files Time audio: 8.200544217687074 Segments 38 \n",
            " Processed 43/143 files Time audio: 2.7931519274376417 Segments 12 \n",
            " Processed 44/143 files Time audio: 2.267437641723356 Segments 9 \n",
            " Processed 44/144 files Time audio: 5.0751700680272105 Segments 23 \n",
            " Processed 45/144 files Time audio: 5.905079365079365 Segments 27 \n",
            " Processed 45/145 files Time audio: 5.661836734693877 Segments 26 \n",
            " Processed 46/145 files Time audio: 4.476530612244898 Segments 20 \n",
            " Processed 46/146 files Time audio: 6.953650793650794 Segments 33 \n",
            " Processed 47/146 files Time audio: 7.582902494331066 Segments 36 \n",
            " Processed 47/147 files Time audio: 2.519614512471655 Segments 10 \n",
            " Processed 48/147 files Time audio: 1.8035827664399093 Segments 7 \n",
            " Processed 48/148 files Time audio: 7.788730158730159 Segments 36 \n",
            " Processed 49/148 files Time audio: 12.240362811791384 Segments 57 \n",
            " Processed 49/149 files Time audio: 5.139591836734694 Segments 23 \n",
            " Processed 50/149 files Time audio: 5.546961451247165 Segments 24 \n",
            " Processed 50/150 files Time audio: 4.688956916099773 Segments 20 \n",
            " Processed 51/150 files Time audio: 5.004172335600907 Segments 22 \n",
            " Processed 51/151 files Time audio: 6.537664399092971 Segments 31 \n",
            " Processed 52/151 files Time audio: 9.617732426303855 Segments 46 \n",
            " Processed 52/152 files Time audio: 3.8930385487528345 Segments 17 \n",
            " Processed 53/152 files Time audio: 2.6459410430839 Segments 11 \n",
            " Processed 53/153 files Time audio: 8.474852607709751 Segments 40 \n",
            " Processed 54/153 files Time audio: 5.530839002267574 Segments 26 \n",
            " Processed 54/154 files Time audio: 3.1004308390022675 Segments 13 \n",
            " Processed 55/154 files Time audio: 1.9997052154195012 Segments 7 \n",
            " Processed 55/155 files Time audio: 4.291269841269841 Segments 19 \n",
            " Processed 56/155 files Time audio: 4.521768707482993 Segments 21 \n",
            " Processed 56/156 files Time audio: 1.9213151927437642 Segments 8 \n",
            " Processed 57/156 files Time audio: 2.3744897959183673 Segments 10 \n",
            " Processed 57/157 files Time audio: 5.183628117913832 Segments 24 \n",
            " Processed 58/157 files Time audio: 6.180680272108844 Segments 29 \n",
            " Processed 58/158 files Time audio: 3.1710657596371883 Segments 14 \n",
            " Processed 59/158 files Time audio: 2.395986394557823 Segments 10 \n",
            " Processed 59/159 files Time audio: 2.4088208616780045 Segments 10 \n",
            " Processed 60/159 files Time audio: 2.110861678004535 Segments 9 \n",
            " Processed 60/160 files Time audio: 5.2766213151927435 Segments 24 \n",
            " Processed 61/160 files Time audio: 5.725510204081632 Segments 27 \n",
            " Processed 61/161 files Time audio: 4.022993197278912 Segments 18 \n",
            " Processed 62/161 files Time audio: 3.229659863945578 Segments 13 \n",
            " Processed 62/162 files Time audio: 6.83687074829932 Segments 32 \n",
            " Processed 63/162 files Time audio: 5.302244897959183 Segments 24 \n",
            " Processed 63/163 files Time audio: 3.3463038548752833 Segments 15 \n",
            " Processed 64/163 files Time audio: 2.9072562358276643 Segments 13 \n",
            " Processed 64/164 files Time audio: 3.8841496598639456 Segments 17 \n",
            " Processed 65/164 files Time audio: 2.9831065759637188 Segments 13 \n",
            " Processed 65/165 files Time audio: 4.7089569160997735 Segments 22 \n",
            " Processed 66/165 files Time audio: 3.4609297052154195 Segments 16 \n",
            " Processed 66/166 files Time audio: 2.6549886621315193 Segments 11 \n",
            " Processed 67/166 files Time audio: 2.1473015873015875 Segments 9 \n",
            " Processed 67/167 files Time audio: 2.1874149659863944 Segments 9 \n",
            " Processed 68/167 files Time audio: 3.7534240362811793 Segments 16 \n",
            " Processed 68/168 files Time audio: 4.846326530612245 Segments 21 \n",
            " Processed 69/168 files Time audio: 3.534716553287982 Segments 15 \n",
            " Processed 69/169 files Time audio: 3.7718820861678006 Segments 16 \n",
            " Processed 70/169 files Time audio: 3.004829931972789 Segments 13 \n",
            " Processed 70/170 files Time audio: 2.3314285714285714 Segments 9 \n",
            " Processed 71/170 files Time audio: 2.4404761904761907 Segments 10 \n",
            " Processed 71/171 files Time audio: 2.944875283446712 Segments 13 \n",
            " Processed 72/171 files Time audio: 3.012358276643991 Segments 13 \n",
            " Processed 72/172 files Time audio: 6.201360544217687 Segments 28 \n",
            " Processed 73/172 files Time audio: 4.786802721088435 Segments 22 \n",
            " Processed 73/173 files Time audio: 7.368299319727891 Segments 34 \n",
            " Processed 74/173 files Time audio: 5.181020408163265 Segments 24 \n",
            " Processed 74/174 files Time audio: 2.4614285714285713 Segments 10 \n",
            " Processed 75/174 files Time audio: 2.7582086167800455 Segments 12 \n",
            " Processed 75/175 files Time audio: 3.6421315192743764 Segments 16 \n",
            " Processed 76/175 files Time audio: 5.418185941043084 Segments 24 \n",
            " Processed 76/176 files Time audio: 2.9742403628117913 Segments 13 \n",
            " Processed 77/176 files Time audio: 1.9146485260770976 Segments 8 \n",
            " Processed 77/177 files Time audio: 3.22843537414966 Segments 14 \n",
            " Processed 78/177 files Time audio: 2.274625850340136 Segments 9 \n",
            " Processed 78/178 files Time audio: 4.743265306122449 Segments 22 \n",
            " Processed 79/178 files Time audio: 5.303945578231293 Segments 24 \n",
            " Processed 79/179 files Time audio: 5.377573696145125 Segments 25 \n",
            " Processed 80/179 files Time audio: 3.6528798185941045 Segments 17 \n",
            " Processed 80/180 files Time audio: 2.5513378684807257 Segments 11 \n",
            " Processed 81/180 files Time audio: 3.4140589569161 Segments 15 \n",
            " Processed 81/181 files Time audio: 7.714943310657596 Segments 36 \n",
            " Processed 82/181 files Time audio: 6.235827664399093 Segments 29 \n",
            " Processed 82/182 files Time audio: 2.765034013605442 Segments 12 \n",
            " Processed 83/182 files Time audio: 1.9330385487528345 Segments 8 \n",
            " Processed 83/183 files Time audio: 3.4314739229024944 Segments 15 \n",
            " Processed 84/183 files Time audio: 2.57172335600907 Segments 11 \n",
            " Processed 84/184 files Time audio: 4.744943310657597 Segments 22 \n",
            " Processed 85/184 files Time audio: 3.650612244897959 Segments 16 \n",
            " Processed 85/185 files Time audio: 4.735328798185941 Segments 21 \n",
            " Processed 86/185 files Time audio: 7.462857142857143 Segments 35 \n",
            " Processed 86/186 files Time audio: 1.9105442176870748 Segments 8 \n",
            " Processed 87/186 files Time audio: 2.330839002267574 Segments 10 \n",
            " Processed 87/187 files Time audio: 1.6822448979591837 Segments 6 \n",
            " Processed 88/187 files Time audio: 1.2458276643990929 Segments 4 \n",
            " Processed 88/188 files Time audio: 4.413832199546485 Segments 20 \n",
            " Processed 89/188 files Time audio: 3.1277777777777778 Segments 14 \n",
            " Processed 89/189 files Time audio: 3.918390022675737 Segments 18 \n",
            " Processed 90/189 files Time audio: 6.223741496598639 Segments 29 \n",
            " Processed 90/190 files Time audio: 4.8749886621315195 Segments 22 \n",
            " Processed 91/190 files Time audio: 3.3838548752834465 Segments 15 \n",
            " Processed 91/191 files Time audio: 4.72625850340136 Segments 21 \n",
            " Processed 92/191 files Time audio: 3.0900907029478457 Segments 13 \n",
            " Processed 92/192 files Time audio: 3.4902721088435373 Segments 15 \n",
            " Processed 93/192 files Time audio: 4.108480725623583 Segments 18 \n",
            " Processed 93/193 files Time audio: 3.509931972789116 Segments 16 \n",
            " Processed 94/193 files Time audio: 2.7056462585034016 Segments 12 \n",
            " Processed 94/194 files Time audio: 2.4535374149659863 Segments 10 \n",
            " Processed 95/194 files Time audio: 2.971678004535147 Segments 13 \n",
            " Processed 95/195 files Time audio: 3.2775056689342406 Segments 14 \n",
            " Processed 96/195 files Time audio: 2.947891156462585 Segments 13 \n",
            " Processed 96/196 files Time audio: 3.83156462585034 Segments 17 \n",
            " Processed 97/196 files Time audio: 2.436689342403628 Segments 10 \n",
            " Processed 97/197 files Time audio: 4.52718820861678 Segments 20 \n",
            " Processed 98/197 files Time audio: 2.8661451247165535 Segments 12 \n",
            " Processed 98/198 files Time audio: 2.7872562358276642 Segments 12 \n",
            " Processed 99/198 files Time audio: 2.4443310657596373 Segments 10 \n",
            " Processed 99/199 files Time audio: 5.023650793650794 Segments 23 \n",
            " Processed 100/199 files Time audio: 7.707210884353741 Segments 36 \n",
            " Processed 100/200 files Time audio: 5.738979591836735 Segments 26 \n",
            " Processed 101/200 files Time audio: 8.533038548752835 Segments 40 \n",
            " Total segments:  3990\n",
            " Total augmentations:  100\n",
            "----------------------------------------\n",
            " Processed 1/101 files Time audio: 3.2960090702947844 Segments 14 \n",
            " Processed 2/101 files Time audio: 3.2960090702947844 Segments 14 \n",
            " Processed 2/102 files Time audio: 7.261950113378685 Segments 34 \n",
            " Processed 3/102 files Time audio: 7.261950113378685 Segments 33 \n",
            " Processed 3/103 files Time audio: 6.469138321995465 Segments 30 \n",
            " Processed 4/103 files Time audio: 6.469138321995465 Segments 30 \n",
            " Processed 4/104 files Time audio: 2.5204761904761903 Segments 9 \n",
            " Processed 5/104 files Time audio: 2.5204761904761903 Segments 9 \n",
            " Processed 5/105 files Time audio: 7.466031746031746 Segments 35 \n",
            " Processed 6/105 files Time audio: 7.466031746031746 Segments 35 \n",
            " Processed 6/106 files Time audio: 6.533945578231292 Segments 30 \n",
            " Processed 7/106 files Time audio: 6.533945578231292 Segments 30 \n",
            " Processed 7/107 files Time audio: 4.915079365079365 Segments 22 \n",
            " Processed 8/107 files Time audio: 4.915079365079365 Segments 22 \n",
            " Processed 8/108 files Time audio: 4.467210884353742 Segments 20 \n",
            " Processed 9/108 files Time audio: 4.467210884353742 Segments 19 \n",
            " Processed 9/109 files Time audio: 3.5493650793650793 Segments 15 \n",
            " Processed 10/109 files Time audio: 3.5493650793650793 Segments 15 \n",
            " Processed 10/110 files Time audio: 10.52297052154195 Segments 50 \n",
            " Processed 11/110 files Time audio: 10.52297052154195 Segments 50 \n",
            " Processed 11/111 files Time audio: 2.988231292517007 Segments 13 \n",
            " Processed 12/111 files Time audio: 2.988231292517007 Segments 13 \n",
            " Processed 12/112 files Time audio: 4.17984126984127 Segments 19 \n",
            " Processed 13/112 files Time audio: 4.17984126984127 Segments 19 \n",
            " Processed 13/113 files Time audio: 3.1898412698412697 Segments 14 \n",
            " Processed 14/113 files Time audio: 3.1898412698412697 Segments 14 \n",
            " Processed 14/114 files Time audio: 6.068208616780045 Segments 28 \n",
            " Processed 15/114 files Time audio: 6.068208616780045 Segments 28 \n",
            " Processed 15/115 files Time audio: 6.781859410430839 Segments 32 \n",
            " Processed 16/115 files Time audio: 6.781859410430839 Segments 31 \n",
            " Processed 16/116 files Time audio: 5.463877551020408 Segments 25 \n",
            " Processed 17/116 files Time audio: 5.463877551020408 Segments 24 \n",
            " Processed 17/117 files Time audio: 6.576893424036281 Segments 30 \n",
            " Processed 18/117 files Time audio: 6.576893424036281 Segments 30 \n",
            " Processed 18/118 files Time audio: 3.325034013605442 Segments 14 \n",
            " Processed 19/118 files Time audio: 3.325034013605442 Segments 15 \n",
            " Processed 19/119 files Time audio: 3.6186394557823127 Segments 16 \n",
            " Processed 20/119 files Time audio: 3.6186394557823127 Segments 16 \n",
            " Processed 20/120 files Time audio: 1.7343990929705215 Segments 7 \n",
            " Processed 21/120 files Time audio: 1.7343990929705215 Segments 7 \n",
            " Processed 21/121 files Time audio: 5.866780045351474 Segments 27 \n",
            " Processed 22/121 files Time audio: 5.866780045351474 Segments 27 \n",
            " Processed 22/122 files Time audio: 3.281859410430839 Segments 14 \n",
            " Processed 23/122 files Time audio: 3.281859410430839 Segments 14 \n",
            " Processed 23/123 files Time audio: 5.842403628117914 Segments 26 \n",
            " Processed 24/123 files Time audio: 5.842403628117914 Segments 26 \n",
            " Processed 24/124 files Time audio: 4.345238095238095 Segments 18 \n",
            " Processed 25/124 files Time audio: 4.345238095238095 Segments 18 \n",
            " Processed 25/125 files Time audio: 1.4207709750566893 Segments 5 \n",
            " Processed 26/125 files Time audio: 1.4207709750566893 Segments 5 \n",
            " Processed 26/126 files Time audio: 2.1656916099773245 Segments 9 \n",
            " Processed 27/126 files Time audio: 2.1656916099773245 Segments 9 \n",
            " Processed 27/127 files Time audio: 2.364512471655329 Segments 10 \n",
            " Processed 28/127 files Time audio: 2.364512471655329 Segments 10 \n",
            " Processed 28/128 files Time audio: 3.318934240362812 Segments 15 \n",
            " Processed 29/128 files Time audio: 3.318934240362812 Segments 15 \n",
            " Processed 29/129 files Time audio: 2.5707482993197277 Segments 11 \n",
            " Processed 30/129 files Time audio: 2.5707482993197277 Segments 11 \n",
            " Processed 30/130 files Time audio: 3.713219954648526 Segments 16 \n",
            " Processed 31/130 files Time audio: 3.713219954648526 Segments 16 \n",
            " Processed 31/131 files Time audio: 6.52859410430839 Segments 30 \n",
            " Processed 32/131 files Time audio: 6.52859410430839 Segments 30 \n",
            " Processed 32/132 files Time audio: 4.131632653061224 Segments 19 \n",
            " Processed 33/132 files Time audio: 4.131632653061224 Segments 19 \n",
            " Processed 33/133 files Time audio: 4.568458049886622 Segments 20 \n",
            " Processed 34/133 files Time audio: 4.568458049886622 Segments 20 \n",
            " Processed 34/134 files Time audio: 6.379342403628118 Segments 30 \n",
            " Processed 35/134 files Time audio: 6.379342403628118 Segments 30 \n",
            " Processed 35/135 files Time audio: 3.768140589569161 Segments 16 \n",
            " Processed 36/135 files Time audio: 3.768140589569161 Segments 16 \n",
            " Processed 36/136 files Time audio: 1.9452380952380952 Segments 7 \n",
            " Processed 37/136 files Time audio: 1.9452380952380952 Segments 8 \n",
            " Processed 37/137 files Time audio: 3.4593197278911565 Segments 15 \n",
            " Processed 38/137 files Time audio: 3.4593197278911565 Segments 15 \n",
            " Processed 38/138 files Time audio: 7.7713378684807255 Segments 36 \n",
            " Processed 39/138 files Time audio: 7.7713378684807255 Segments 36 \n",
            " Processed 39/139 files Time audio: 1.3895238095238096 Segments 5 \n",
            " Processed 40/139 files Time audio: 1.3895238095238096 Segments 5 \n",
            " Processed 40/140 files Time audio: 6.407369614512471 Segments 30 \n",
            " Processed 41/140 files Time audio: 6.407369614512471 Segments 30 \n",
            " Processed 41/141 files Time audio: 5.553083900226757 Segments 25 \n",
            " Processed 42/141 files Time audio: 5.553083900226757 Segments 25 \n",
            " Processed 42/142 files Time audio: 6.140181405895691 Segments 28 \n",
            " Processed 43/142 files Time audio: 6.140181405895691 Segments 28 \n",
            " Processed 43/143 files Time audio: 2.7931519274376417 Segments 12 \n",
            " Processed 44/143 files Time audio: 2.7931519274376417 Segments 12 \n",
            " Processed 44/144 files Time audio: 5.0751700680272105 Segments 23 \n",
            " Processed 45/144 files Time audio: 5.0751700680272105 Segments 23 \n",
            " Processed 45/145 files Time audio: 5.661836734693877 Segments 26 \n",
            " Processed 46/145 files Time audio: 5.661836734693877 Segments 26 \n",
            " Processed 46/146 files Time audio: 6.953650793650794 Segments 33 \n",
            " Processed 47/146 files Time audio: 6.953650793650794 Segments 33 \n",
            " Processed 47/147 files Time audio: 2.519614512471655 Segments 10 \n",
            " Processed 48/147 files Time audio: 2.519614512471655 Segments 10 \n",
            " Processed 48/148 files Time audio: 7.788730158730159 Segments 36 \n",
            " Processed 49/148 files Time audio: 7.788730158730159 Segments 36 \n",
            " Processed 49/149 files Time audio: 5.139591836734694 Segments 23 \n",
            " Processed 50/149 files Time audio: 5.139591836734694 Segments 22 \n",
            " Processed 50/150 files Time audio: 4.688956916099773 Segments 20 \n",
            " Processed 51/150 files Time audio: 4.688956916099773 Segments 21 \n",
            " Processed 51/151 files Time audio: 6.537664399092971 Segments 31 \n",
            " Processed 52/151 files Time audio: 6.537664399092971 Segments 31 \n",
            " Processed 52/152 files Time audio: 3.8930385487528345 Segments 17 \n",
            " Processed 53/152 files Time audio: 3.8930385487528345 Segments 17 \n",
            " Processed 53/153 files Time audio: 8.474852607709751 Segments 40 \n",
            " Processed 54/153 files Time audio: 8.474852607709751 Segments 40 \n",
            " Processed 54/154 files Time audio: 3.1004308390022675 Segments 13 \n",
            " Processed 55/154 files Time audio: 3.1004308390022675 Segments 12 \n",
            " Processed 55/155 files Time audio: 4.291269841269841 Segments 19 \n",
            " Processed 56/155 files Time audio: 4.291269841269841 Segments 19 \n",
            " Processed 56/156 files Time audio: 1.9213151927437642 Segments 8 \n",
            " Processed 57/156 files Time audio: 1.9213151927437642 Segments 8 \n",
            " Processed 57/157 files Time audio: 5.183628117913832 Segments 24 \n",
            " Processed 58/157 files Time audio: 5.183628117913832 Segments 24 \n",
            " Processed 58/158 files Time audio: 3.1710657596371883 Segments 14 \n",
            " Processed 59/158 files Time audio: 3.1710657596371883 Segments 14 \n",
            " Processed 59/159 files Time audio: 2.4088208616780045 Segments 10 \n",
            " Processed 60/159 files Time audio: 2.4088208616780045 Segments 10 \n",
            " Processed 60/160 files Time audio: 5.2766213151927435 Segments 24 \n",
            " Processed 61/160 files Time audio: 5.2766213151927435 Segments 24 \n",
            " Processed 61/161 files Time audio: 4.022993197278912 Segments 18 \n",
            " Processed 62/161 files Time audio: 4.022993197278912 Segments 18 \n",
            " Processed 62/162 files Time audio: 6.83687074829932 Segments 32 \n",
            " Processed 63/162 files Time audio: 6.83687074829932 Segments 32 \n",
            " Processed 63/163 files Time audio: 3.3463038548752833 Segments 15 \n",
            " Processed 64/163 files Time audio: 3.3463038548752833 Segments 15 \n",
            " Processed 64/164 files Time audio: 3.8841496598639456 Segments 17 \n",
            " Processed 65/164 files Time audio: 3.8841496598639456 Segments 17 \n",
            " Processed 65/165 files Time audio: 4.7089569160997735 Segments 22 \n",
            " Processed 66/165 files Time audio: 4.7089569160997735 Segments 22 \n",
            " Processed 66/166 files Time audio: 2.6549886621315193 Segments 11 \n",
            " Processed 67/166 files Time audio: 2.6549886621315193 Segments 11 \n",
            " Processed 67/167 files Time audio: 2.1874149659863944 Segments 9 \n",
            " Processed 68/167 files Time audio: 2.1874149659863944 Segments 9 \n",
            " Processed 68/168 files Time audio: 4.846326530612245 Segments 21 \n",
            " Processed 69/168 files Time audio: 4.846326530612245 Segments 21 \n",
            " Processed 69/169 files Time audio: 3.7718820861678006 Segments 16 \n",
            " Processed 70/169 files Time audio: 3.7718820861678006 Segments 16 \n",
            " Processed 70/170 files Time audio: 2.3314285714285714 Segments 9 \n",
            " Processed 71/170 files Time audio: 2.3314285714285714 Segments 9 \n",
            " Processed 71/171 files Time audio: 2.944875283446712 Segments 13 \n",
            " Processed 72/171 files Time audio: 2.944875283446712 Segments 13 \n",
            " Processed 72/172 files Time audio: 6.201360544217687 Segments 28 \n",
            " Processed 73/172 files Time audio: 6.201360544217687 Segments 29 \n",
            " Processed 73/173 files Time audio: 7.368299319727891 Segments 34 \n",
            " Processed 74/173 files Time audio: 7.368299319727891 Segments 34 \n",
            " Processed 74/174 files Time audio: 2.4614285714285713 Segments 10 \n",
            " Processed 75/174 files Time audio: 2.4614285714285713 Segments 10 \n",
            " Processed 75/175 files Time audio: 3.6421315192743764 Segments 16 \n",
            " Processed 76/175 files Time audio: 3.6421315192743764 Segments 16 \n",
            " Processed 76/176 files Time audio: 2.9742403628117913 Segments 13 \n",
            " Processed 77/176 files Time audio: 2.9742403628117913 Segments 12 \n",
            " Processed 77/177 files Time audio: 3.22843537414966 Segments 14 \n",
            " Processed 78/177 files Time audio: 3.22843537414966 Segments 13 \n",
            " Processed 78/178 files Time audio: 4.743265306122449 Segments 22 \n",
            " Processed 79/178 files Time audio: 4.743265306122449 Segments 22 \n",
            " Processed 79/179 files Time audio: 5.377573696145125 Segments 25 \n",
            " Processed 80/179 files Time audio: 5.377573696145125 Segments 25 \n",
            " Processed 80/180 files Time audio: 2.5513378684807257 Segments 11 \n",
            " Processed 81/180 files Time audio: 2.5513378684807257 Segments 11 \n",
            " Processed 81/181 files Time audio: 7.714943310657596 Segments 36 \n",
            " Processed 82/181 files Time audio: 7.714943310657596 Segments 36 \n",
            " Processed 82/182 files Time audio: 2.765034013605442 Segments 12 \n",
            " Processed 83/182 files Time audio: 2.765034013605442 Segments 12 \n",
            " Processed 83/183 files Time audio: 3.4314739229024944 Segments 15 \n",
            " Processed 84/183 files Time audio: 3.4314739229024944 Segments 15 \n",
            " Processed 84/184 files Time audio: 4.744943310657597 Segments 22 \n",
            " Processed 85/184 files Time audio: 4.744943310657597 Segments 21 \n",
            " Processed 85/185 files Time audio: 4.735328798185941 Segments 21 \n",
            " Processed 86/185 files Time audio: 4.735328798185941 Segments 21 \n",
            " Processed 86/186 files Time audio: 1.9105442176870748 Segments 8 \n",
            " Processed 87/186 files Time audio: 1.9105442176870748 Segments 8 \n",
            " Processed 87/187 files Time audio: 1.6822448979591837 Segments 6 \n",
            " Processed 88/187 files Time audio: 1.6822448979591837 Segments 6 \n",
            " Processed 88/188 files Time audio: 4.413832199546485 Segments 20 \n",
            " Processed 89/188 files Time audio: 4.413832199546485 Segments 20 \n",
            " Processed 89/189 files Time audio: 3.918390022675737 Segments 18 \n",
            " Processed 90/189 files Time audio: 3.918390022675737 Segments 18 \n",
            " Processed 90/190 files Time audio: 4.8749886621315195 Segments 22 \n",
            " Processed 91/190 files Time audio: 4.8749886621315195 Segments 22 \n",
            " Processed 91/191 files Time audio: 4.72625850340136 Segments 21 \n",
            " Processed 92/191 files Time audio: 4.72625850340136 Segments 21 \n",
            " Processed 92/192 files Time audio: 3.4902721088435373 Segments 15 \n",
            " Processed 93/192 files Time audio: 3.4902721088435373 Segments 15 \n",
            " Processed 93/193 files Time audio: 3.509931972789116 Segments 16 \n",
            " Processed 94/193 files Time audio: 3.509931972789116 Segments 16 \n",
            " Processed 94/194 files Time audio: 2.4535374149659863 Segments 10 \n",
            " Processed 95/194 files Time audio: 2.4535374149659863 Segments 10 \n",
            " Processed 95/195 files Time audio: 3.2775056689342406 Segments 14 \n",
            " Processed 96/195 files Time audio: 3.2775056689342406 Segments 14 \n",
            " Processed 96/196 files Time audio: 3.83156462585034 Segments 17 \n",
            " Processed 97/196 files Time audio: 3.83156462585034 Segments 17 \n",
            " Processed 97/197 files Time audio: 4.52718820861678 Segments 20 \n",
            " Processed 98/197 files Time audio: 4.52718820861678 Segments 20 \n",
            " Processed 98/198 files Time audio: 2.7872562358276642 Segments 12 \n",
            " Processed 99/198 files Time audio: 2.7872562358276642 Segments 12 \n",
            " Processed 99/199 files Time audio: 5.023650793650794 Segments 23 \n",
            " Processed 100/199 files Time audio: 5.023650793650794 Segments 23 \n",
            " Processed 100/200 files Time audio: 5.738979591836735 Segments 26 \n",
            " Processed 101/200 files Time audio: 5.738979591836735 Segments 26 \n",
            " Total segments:  3919\n",
            " Total augmentations:  100\n",
            "----------------------------------------\n",
            " Processed 134/86 files Time audio: 20.82548752834467 Segments 102 \n",
            " Processed 160/86 files Time audio: 15.305170068027211 Segments 75 \n",
            " Processed 149/86 files Time audio: 21.0797052154195 Segments 103 \n",
            " Processed 153/86 files Time audio: 5.784807256235828 Segments 27 \n",
            " Processed 136/86 files Time audio: 11.495124716553288 Segments 56 \n",
            " Processed 155/86 files Time audio: 11.823990929705216 Segments 57 \n",
            " Processed 151/86 files Time audio: 10.284331065759638 Segments 49 \n",
            " Processed 156/86 files Time audio: 9.943514739229025 Segments 48 \n",
            " Processed 152/86 files Time audio: 11.875124716553287 Segments 58 \n",
            " Processed 148/86 files Time audio: 9.69015873015873 Segments 47 \n",
            " Processed 154/86 files Time audio: 10.044625850340136 Segments 48 \n",
            " Processed 237/86 files Time audio: 22.476485260770975 Segments 109 \n",
            " Processed 222/86 files Time audio: 8.724807256235827 Segments 40 \n",
            " Processed 161/86 files Time audio: 11.351360544217687 Segments 55 \n",
            " Processed 205/86 files Time audio: 6.616802721088435 Segments 31 \n",
            " Processed 242/86 files Time audio: 18.445804988662132 Segments 90 \n",
            " Processed 162/86 files Time audio: 19.57950113378685 Segments 96 \n",
            " Processed 243/86 files Time audio: 20.52641723356009 Segments 101 \n",
            " Processed 182/86 files Time audio: 10.61439909297052 Segments 51 \n",
            " Processed 186/86 files Time audio: 6.476916099773242 Segments 31 \n",
            " Processed 172/86 files Time audio: 9.896984126984126 Segments 48 \n",
            " Processed 185/86 files Time audio: 11.197437641723356 Segments 54 \n",
            " Processed 164/86 files Time audio: 2.3939002267573697 Segments 10 \n",
            " Processed 212/86 files Time audio: 15.312063492063492 Segments 74 \n",
            " Processed 175/86 files Time audio: 18.465034013605443 Segments 91 \n",
            " Processed 240/86 files Time audio: 11.826281179138322 Segments 57 \n",
            " Processed 231/86 files Time audio: 7.6682993197278915 Segments 36 \n",
            " Processed 163/86 files Time audio: 5.358163265306122 Segments 25 \n",
            " Processed 232/86 files Time audio: 17.551269841269843 Segments 85 \n",
            " Processed 238/86 files Time audio: 10.636621315192743 Segments 49 \n",
            " Processed 230/86 files Time audio: 18.816598639455783 Segments 91 \n",
            " Processed 216/86 files Time audio: 7.956054421768708 Segments 37 \n",
            " Processed 241/86 files Time audio: 11.533151927437642 Segments 54 \n",
            " Processed 236/86 files Time audio: 24.995668934240364 Segments 120 \n",
            " Processed 220/86 files Time audio: 20.51238095238095 Segments 99 \n",
            " Processed 228/86 files Time audio: 26.934784580498867 Segments 131 \n",
            " Processed 176/86 files Time audio: 13.768548752834468 Segments 67 \n",
            " Processed 218/86 files Time audio: 11.604897959183674 Segments 55 \n",
            " Processed 234/86 files Time audio: 18.41031746031746 Segments 88 \n",
            " Processed 181/86 files Time audio: 14.38 Segments 69 \n",
            " Processed 245/86 files Time audio: 12.074353741496598 Segments 59 \n",
            " Processed 174/86 files Time audio: 5.498684807256236 Segments 26 \n",
            " Processed 127/86 files Time audio: 21.99251700680272 Segments 108 \n",
            " Processed 113/86 files Time audio: 14.364671201814058 Segments 70 \n",
            " Processed 140/86 files Time audio: 7.806507936507937 Segments 37 \n",
            " Processed 118/86 files Time audio: 20.88886621315193 Segments 103 \n",
            " Processed 115/86 files Time audio: 8.445668934240363 Segments 40 \n",
            " Processed 117/86 files Time audio: 12.863718820861678 Segments 62 \n",
            " Processed 125/86 files Time audio: 5.60875283446712 Segments 26 \n",
            " Processed 129/86 files Time audio: 4.504603174603175 Segments 21 \n",
            " Processed 139/86 files Time audio: 8.51047619047619 Segments 41 \n",
            " Processed 108/86 files Time audio: 10.103356009070295 Segments 49 \n",
            " Processed 112/86 files Time audio: 3.9514739229024944 Segments 18 \n",
            " Processed 106/86 files Time audio: 3.3710430839002266 Segments 15 \n",
            " Processed 109/86 files Time audio: 6.393877551020408 Segments 30 \n",
            " Processed 133/86 files Time audio: 21.45326530612245 Segments 106 \n",
            " Processed 132/86 files Time audio: 6.925215419501134 Segments 33 \n",
            " Processed 138/86 files Time audio: 18.346031746031745 Segments 90 \n",
            " Processed 107/86 files Time audio: 9.109614512471655 Segments 44 \n",
            " Processed 130/86 files Time audio: 11.032675736961451 Segments 53 \n",
            " Processed 124/86 files Time audio: 9.03795918367347 Segments 43 \n",
            " Processed 111/86 files Time audio: 12.743197278911564 Segments 62 \n",
            " Processed 141/86 files Time audio: 12.07031746031746 Segments 59 \n",
            " Processed 142/86 files Time audio: 16.683718820861678 Segments 82 \n",
            " Processed 137/86 files Time audio: 4.344489795918367 Segments 20 \n",
            " Processed 110/86 files Time audio: 7.265124716553288 Segments 35 \n",
            " Processed 120/86 files Time audio: 10.693038548752835 Segments 51 \n",
            " Processed 135/86 files Time audio: 5.900226757369614 Segments 27 \n",
            " Processed 119/86 files Time audio: 9.860340136054422 Segments 48 \n",
            " Processed 116/86 files Time audio: 17.822244897959184 Segments 87 \n",
            " Processed 131/86 files Time audio: 7.613424036281179 Segments 36 \n",
            " Processed 128/86 files Time audio: 13.091814058956917 Segments 64 \n",
            " Processed 168/86 files Time audio: 6.251111111111111 Segments 29 \n",
            " Processed 144/86 files Time audio: 15.367573696145124 Segments 75 \n",
            " Processed 177/86 files Time audio: 11.23702947845805 Segments 54 \n",
            " Processed 146/86 files Time audio: 10.024807256235828 Segments 48 \n",
            " Processed 211/86 files Time audio: 19.439591836734692 Segments 94 \n",
            " Processed 166/86 files Time audio: 7.47984126984127 Segments 36 \n",
            " Processed 209/86 files Time audio: 13.488888888888889 Segments 65 \n",
            " Processed 213/86 files Time audio: 12.348775510204081 Segments 59 \n",
            " Processed 169/86 files Time audio: 3.4393197278911565 Segments 15 \n",
            " Processed 215/86 files Time audio: 6.00172335600907 Segments 28 \n",
            " Processed 147/86 files Time audio: 11.155827664399093 Segments 54 \n",
            " Processed 217/86 files Time audio: 12.621655328798186 Segments 59 \n",
            " Processed 170/86 files Time audio: 8.55031746031746 Segments 38 \n",
            " Processed 143/86 files Time audio: 14.73766439909297 Segments 72 \n",
            " Total segments:  4985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Espectrogramas\n",
        "Aquí se realiza el data augmentation.\n",
        "https://pytorch.org/audio/main/generated/torchaudio.transforms.TimeMasking.html#torchaudio.transforms.TimeMasking\n",
        "https://paperswithcode.com/paper/specaugment-a-simple-data-augmentation-method"
      ],
      "metadata": {
        "id": "KgUeGFjKrdOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_norm_spect(signals, sample_rate, want_to_augment = True):\n",
        "    n_fft = 2048\n",
        "    win_length = int(0.015*sample_rate)\n",
        "    hop_length = int(0.010*sample_rate)\n",
        "    n_mels = 65\n",
        "\n",
        "    augmentation_count = 0\n",
        "    if want_to_augment:\n",
        "      time_masking = T.TimeMasking(time_mask_param=10)\n",
        "      freq_masking = T.FrequencyMasking(freq_mask_param=14)\n",
        "      aug_mel_spectrograms = []\n",
        "\n",
        "    mel_spectrogram = T.MelSpectrogram(  #T from torchaudio.transforms. Configuración del espectrograma de Mel\n",
        "        sample_rate=sample_rate,\n",
        "        n_fft=n_fft,\n",
        "        win_length=win_length,\n",
        "        hop_length=hop_length,\n",
        "        center=True,\n",
        "        pad_mode=\"reflect\",\n",
        "        power=2.0,\n",
        "        norm=\"slaney\",\n",
        "        #onesided=True,\n",
        "        n_mels=n_mels,\n",
        "        mel_scale=\"htk\",\n",
        "    )\n",
        "\n",
        "\n",
        "    mel_spectrograms = []\n",
        "    scaler = StandardScaler()\n",
        "    print(\"Calculating mel spectrograms\")\n",
        "    for i in range(signals.shape[0]):\n",
        "        mel_spect = librosa.power_to_db(mel_spectrogram(torch.from_numpy(signals[i,:])))\n",
        "        mel_spect_norm=scaler.fit_transform(mel_spect)\n",
        "        mel_spectrograms.append(mel_spect_norm)\n",
        "        print(\"\\r Processed {}/{} files\".format(i + augmentation_count,signals.shape[0] + augmentation_count),end='')\n",
        "\n",
        "        #Data augment\n",
        "        if want_to_augment:\n",
        "          prob_aug = random.random()\n",
        "          if prob_aug <= 1: # All data is augmented\n",
        "              aug_mel_spec = freq_masking(time_masking(torch.from_numpy(mel_spect_norm))) #Apply FreqMasking and TimeMasking to the mel_spect\n",
        "              aug_mel_spectrograms.append(aug_mel_spec)\n",
        "              augmentation_count += 1\n",
        "              print(\"\\r Processed {}/{} files\".format(i + augmentation_count,signals.shape[0] + augmentation_count),end='')\n",
        "\n",
        "    mel_spectrograms = np.stack(mel_spectrograms,axis=0)\n",
        "\n",
        "    if want_to_augment:\n",
        "      aug_mel_spectrograms = np.stack(aug_mel_spectrograms,axis=0) #Descomentar si se vuelve a tener data Aug\n",
        "      print(' ')\n",
        "      return mel_spectrograms, aug_mel_spectrograms\n",
        "    else:\n",
        "      print(' ')\n",
        "      return mel_spectrograms"
      ],
      "metadata": {
        "id": "kePzTHqB3KbC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ESTE SE EJECUTA SI O SI (CALCULAMOS ESPECTROGRAMAS)\n",
        "mel_spectrograms_train_Gita, specAugm_mel_spec=compute_norm_spect(signals_train_Gita, SAMPLE_RATE)\n",
        "print('Data size:',mel_spectrograms_train_Gita.shape)\n",
        "print(\"-\"*40)\n",
        "\n",
        "speed_mel_spec=compute_norm_spect(aug_signals_speed, SAMPLE_RATE, want_to_augment = False)\n",
        "\n",
        "print(\"-\"*40)\n",
        "pitch_mel_spec=compute_norm_spect(aug_signals_pitch, SAMPLE_RATE, want_to_augment = False)\n",
        "\n",
        "print(\"-\"*40)\n",
        "#Data test\n",
        "mel_spectrograms_test_NeuroV=compute_norm_spect(signals_test_NeuroV, SAMPLE_RATE, want_to_augment = False)\n",
        "print('Data size:',mel_spectrograms_test_NeuroV.shape)"
      ],
      "metadata": {
        "id": "Jcy40l1F3PpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6acebf22-63c5-46dd-be5b-2facddfb68a4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating mel spectrograms\n",
            " Processed 3923/3924 files \n",
            "Data size: (1962, 65, 41)\n",
            "----------------------------------------\n",
            "Calculating mel spectrograms\n",
            " Processed 2027/2028 files \n",
            "----------------------------------------\n",
            "Calculating mel spectrograms\n",
            " Processed 1956/1957 files \n",
            "----------------------------------------\n",
            "Calculating mel spectrograms\n",
            " Processed 4984/4985 files \n",
            "Data size: (4985, 65, 41)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prueba 1: Speed + pitch"
      ],
      "metadata": {
        "id": "xQu7JVQzR3pC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aug_mel_spectrograms = np.concatenate([speed_mel_spec, pitch_mel_spec], axis=0)\n",
        "aug_labels = np.concatenate([aug_labels_speed, aug_labels_pitch], axis=0)\n",
        "aug_groups = np.concatenate([aug_groups_speed, aug_groups_pitch], axis=0)"
      ],
      "metadata": {
        "id": "QtNy0Jt5wlTf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Size augmented signals: {}\".format(aug_mel_spectrograms.shape))\n",
        "print(\"Size augmented labels: {}\".format(aug_labels.shape))\n",
        "print(\"Size augmented groups: {}\".format(aug_groups.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwcPz59xbD4J",
        "outputId": "ca4ef2c0-a6de-4f40-a490-dd59cc6cf48e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size augmented signals: (3952, 65, 41)\n",
            "Size augmented labels: (3952,)\n",
            "Size augmented groups: (3952,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prueba 2: Speed + spec"
      ],
      "metadata": {
        "id": "8ZtqJP7USbhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aug_mel_spectrograms = np.concatenate([speed_mel_spec, specAugm_mel_spec], axis=0)\n",
        "aug_labels = np.concatenate([aug_labels_speed, y_label_train_Gita], axis=0)\n",
        "aug_groups = np.concatenate([aug_groups_speed, (subject_group_train_Gita + 1000)], axis=0)"
      ],
      "metadata": {
        "id": "UgMA4Eb5Sbhy"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Size augmented signals: {}\".format(aug_mel_spectrograms.shape))\n",
        "print(\"Size augmented labels: {}\".format(aug_labels.shape))\n",
        "print(\"Size augmented groups: {}\".format(aug_groups.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zn5lelNoSbhy",
        "outputId": "79436bcc-6687-4942-ffe0-a0b8d4f33314"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size augmented signals: (3990, 65, 41)\n",
            "Size augmented labels: (3990,)\n",
            "Size augmented groups: (3990,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prueba 3: pitch + spec"
      ],
      "metadata": {
        "id": "gGsvkOsehGS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aug_mel_spectrograms = np.concatenate([pitch_mel_spec, specAugm_mel_spec], axis=0)\n",
        "aug_labels = np.concatenate([aug_labels_pitch, y_label_train_Gita], axis=0)\n",
        "aug_groups = np.concatenate([aug_groups_pitch, (subject_group_train_Gita + 1000)], axis=0)"
      ],
      "metadata": {
        "id": "gGKWEZMahGTK"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Size augmented signals: {}\".format(aug_mel_spectrograms.shape))\n",
        "print(\"Size augmented labels: {}\".format(aug_labels.shape))\n",
        "print(\"Size augmented groups: {}\".format(aug_groups.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edbb3291-3682-40b2-b0dd-e5d805ac0184",
        "id": "JHoJVPjyhGTL"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size augmented signals: (3919, 65, 41)\n",
            "Size augmented labels: (3919,)\n",
            "Size augmented groups: (3919,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diseño y entrenamiento de la red convolucional"
      ],
      "metadata": {
        "id": "9_uPYYbqq8Ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "\n",
        "        def __init__(self, kernel_size_1=8, kernel_size_2=9, depth_CL=64, neurons_MLP=64, drop_out=0.2):\n",
        "            super().__init__()\n",
        "\n",
        "            # 1. conv block\n",
        "            self.conv2Dblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1,\n",
        "                       out_channels=depth_CL,\n",
        "                       kernel_size=kernel_size_1,\n",
        "                       stride=1,\n",
        "                       padding=1\n",
        "                      ),\n",
        "            nn.BatchNorm2d(depth_CL),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout(p=drop_out),\n",
        "            )\n",
        "\n",
        "            # 2. conv block\n",
        "            self.conv2Dblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=depth_CL,\n",
        "                       out_channels=depth_CL,\n",
        "                       kernel_size=kernel_size_2,\n",
        "                       stride=1,\n",
        "                       padding=1\n",
        "                      ),\n",
        "            nn.BatchNorm2d(depth_CL),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout(p=drop_out),\n",
        "\n",
        "            )\n",
        "\n",
        "            self.MLP = nn.Sequential(\n",
        "                nn.Linear(depth_CL*math.ceil((math.ceil((65-kernel_size_1)/2+1)-kernel_size_2)/2+1)\n",
        "                          *math.ceil((math.ceil((41-kernel_size_1)/2+1)-kernel_size_2)/2+1),neurons_MLP),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=drop_out),\n",
        "            )\n",
        "\n",
        "            self.out_softmax = nn.Sequential(\n",
        "                nn.Linear(neurons_MLP,2),\n",
        "                nn.Softmax(dim=1)\n",
        "            )\n",
        "\n",
        "\n",
        "        def forward(self,x):\n",
        "            x = self.conv2Dblock1(x)\n",
        "            conv_embedding = self.conv2Dblock2(x)\n",
        "            conv_embedding = torch.flatten(conv_embedding, start_dim=1)\n",
        "            MPL_output = self.MLP(conv_embedding)\n",
        "            output_softmax = self.out_softmax(MPL_output)\n",
        "            return output_softmax, MPL_output"
      ],
      "metadata": {
        "id": "NeucVhojq7N3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reset_weights(m):\n",
        "    for layer in m.children():\n",
        "        if hasattr(layer, 'reset_parameters'):\n",
        "            layer.reset_parameters()\n",
        "\n",
        "def soft_output_by_subject(output_test, Y_test, subject_group_test, ):\n",
        "\n",
        "    Y_test_bySubject= []\n",
        "    output_test_bySubjects=torch.empty((1,2),device=output_test.device.type)\n",
        "    subject_in_group=np.unique(subject_group_test)\n",
        "    output_test_subject=torch.zeros(subject_in_group.shape)\n",
        "    Y_estimated_test_subject=torch.ones(subject_in_group.shape)\n",
        "    for i, speaker in enumerate(subject_in_group):\n",
        "        index_speaker = np.where(subject_group_test==speaker)\n",
        "        output_test_subject[i]=torch.mean(torch.log(output_test[index_speaker][:,1]) -torch.log(output_test[index_speaker][:,0]),0)\n",
        "        Y_test_bySubject.append(Y_test[index_speaker][0])\n",
        "\n",
        "\n",
        "    Y_test_tensor_bySubject = torch.tensor(Y_test_bySubject,dtype=torch.long,device=device)\n",
        "    Y_estimated_test_subject[output_test_subject<0]=0\n",
        "    return output_test_subject , Y_test_tensor_bySubject,Y_estimated_test_subject"
      ],
      "metadata": {
        "id": "9dvSRpyns8y8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgkf = StratifiedGroupKFold(n_splits=10)\n",
        "\n",
        "Data_Gita_strat=sgkf.split(mel_spectrograms_train_Gita, y=y_label_train_Gita, groups=subject_group_train_Gita)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "if device=='cuda':\n",
        "    print(\"cuda\")\n",
        "    #torch.cuda.set_device(1)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "\n",
        "#Data to test NeuroV\n",
        "X_test_NeuroV =np.expand_dims(np.stack(mel_spectrograms_test_NeuroV, axis=0),1)\n",
        "Y_test_NeuroV= y_label_test_NeuroV\n",
        "X_test_tensor_NeuroV = torch.tensor(X_test_NeuroV,device=device).float()\n",
        "Y_test_tensor_NeuroV = torch.tensor(Y_test_NeuroV,dtype=torch.long,device=device)\n",
        "\n",
        "\n",
        "#Métricas del modelo\n",
        "results_val_metric_subject_Gita  = []\n",
        "Subject_Sen_spe_Gita, Subject_f1_score_Gita, Subject_MCC_Gita, Subject_AUC_Gita=[],[],[],[]\n",
        "Subject_fpr_Gita, Subject_tpr_Gita=[],[]\n",
        "results_loss_Epochs, results_metric_Epochs= [], []\n",
        "results_val_metric_Gita_Epochs, results_val_loss_Gita_Epochs=[],[]\n",
        "\n",
        "#Métricas de validación con el mismo dataset\n",
        "val_windows_metrics_Gita, val_subject_metrics_Gita=[],[]\n",
        "\n",
        "#Para test con Neurovoz\n",
        "test_windows_metrics_NeuroV, test_subject_metrics_NeuroV=[],[]\n",
        "\n",
        "#Para T-SNE:\n",
        "flattern_train_CNN_Original, Y_train_Original_fold =[],[]\n",
        "flattern_train_CNN_Augmented, Y_train_Augmented_fold =[],[]\n",
        "\n",
        "#Para Covarianza y divergencia\n",
        "Y_Original_fold=[]\n",
        "Y_Augmented_fold =[]\n",
        "#flattern_output_CNN_Original, Y_val_Original_fold=[],[]\n",
        "#flattern_output_CNN_Augmented, Y_val_Augmented_fold =[],[]\n",
        "\n",
        "for k in range(10):\n",
        "    results_loss, results_metric, results_val_metric_Gita, results_val_loss_Gita,  = [], [], [], []\n",
        "\n",
        "\n",
        "    print('')\n",
        "    print(f\"\\k-fold {k + 1} \\n***********************\")\n",
        "\n",
        "    train_index_Gita, val_index_Gita =next(iter(Data_Gita_strat))\n",
        "\n",
        "    print(np.unique(subject_group_train_Gita[val_index_Gita])) #Imprimo los índices que serán usados en validation\n",
        "\n",
        "\n",
        "    #Variables para T-SNE\n",
        "    X_Original = np.expand_dims(np.stack(mel_spectrograms_train_Gita[train_index_Gita,:,:], axis=0),1)\n",
        "    X_tensor_Original = torch.tensor(X_Original,device=device).float()\n",
        "    Y_tensor_Original = torch.tensor(y_label_train_Gita[train_index_Gita], dtype=torch.long,device=device)\n",
        "\n",
        "    X_Augmented = np.expand_dims(np.stack(aug_mel_spectrograms, axis=0),1)\n",
        "    X_tensor_Augmented = torch.tensor(X_Augmented,device=device).float()\n",
        "    Y_tensor_Augmented = torch.tensor(aug_labels, dtype=torch.long,device=device)\n",
        "\n",
        "    #Data to train. Augmented variables: aug_signals, aug_labels, aug_groups, aug_mel_spectrograms\n",
        "\n",
        "    X_train = np.expand_dims(np.stack(np.concatenate([mel_spectrograms_train_Gita[train_index_Gita,:,:], aug_mel_spectrograms], axis=0), axis=0),1) #Acá poner + augmentedSpec\n",
        "    Y_train = np.concatenate([y_label_train_Gita[train_index_Gita], aug_labels],axis=0) #Aca igua ponerle las de augmented\n",
        "\n",
        "    X_tensor = torch.tensor(X_train,device=device).float()\n",
        "    Y_tensor = torch.tensor(Y_train, dtype=torch.long,device=device)\n",
        "\n",
        "    subject_group_train=np.concatenate([subject_group_train_Gita[train_index_Gita], aug_groups],axis=0)#Acá igual concatenar las de augmented\n",
        "\n",
        "\n",
        "    #Data to val Gita\n",
        "    X_val_Gita =np.expand_dims(np.stack(mel_spectrograms_train_Gita[val_index_Gita,:,:], axis=0),1)\n",
        "    Y_val_Gita= y_label_train_Gita[val_index_Gita]\n",
        "    subject_group_val_Gita=subject_group_train_Gita[val_index_Gita]\n",
        "    X_val_tensor_Gita = torch.tensor(X_val_Gita,device=device).float()\n",
        "    Y_val_tensor_Gita = torch.tensor(Y_val_Gita,dtype=torch.long,device=device)\n",
        "\n",
        "\n",
        "    DATASET_SIZE=X_train.shape[0]\n",
        "    iters = int(DATASET_SIZE / BATCH_SIZE)\n",
        "\n",
        "    model = CNN().to(device)\n",
        "    model.apply(reset_weights)\n",
        "\n",
        "\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
        "    lambda1 = lambda epoch: 0.95 ** epoch\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n",
        "\n",
        "\n",
        "    dataset=TensorDataset(X_tensor,Y_tensor)\n",
        "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    for epoch in range(100): #100 épocas\n",
        "        epoch_acc = 0\n",
        "        epoch_loss = 0\n",
        "        for id_batch, (x_batch, y_batch) in enumerate(dataloader):\n",
        "            actual_batch_size=x_batch.shape[0]\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            outputs = model(x_batch)[0]\n",
        "\n",
        "            # calculate accuracy\n",
        "            prediction = torch.max(outputs, 1)[1]\n",
        "            metric = sklearn.metrics.accuracy_score(y_batch.data.cpu(), prediction.data.cpu())*100\n",
        "\n",
        "\n",
        "            # calculate loss + backward + optimize\n",
        "            loss = loss_func(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_acc += metric*actual_batch_size/DATASET_SIZE\n",
        "            epoch_loss += loss.item()*actual_batch_size/DATASET_SIZE\n",
        "        print(f\"\\r Epoch {epoch +1}: iteration {id_batch +1}/{iters} Acc_class: {epoch_acc:.2f}\",end='')\n",
        "\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            output_val_Gita = model(X_val_tensor_Gita)[0]\n",
        "            prediction_val_Gita = torch.max(output_val_Gita, 1)[1]\n",
        "            val_metric_Gita = sklearn.metrics.accuracy_score(Y_val_tensor_Gita.data.cpu(), prediction_val_Gita.data.cpu())*100\n",
        "            val_loss_Gita = loss_func(output_val_Gita, Y_val_tensor_Gita.data)\n",
        "\n",
        "            output_val_bySubjects_Gita, Y_val_tensor_bySubject_Gita, prediction_val_bySubject_Gita =soft_output_by_subject(output_val_Gita, Y_val_Gita, subject_group_val_Gita)\n",
        "            val_metric_subject_Gita = sklearn.metrics.accuracy_score(Y_val_tensor_bySubject_Gita.data.cpu(), prediction_val_bySubject_Gita.data.cpu())*100\n",
        "\n",
        "        # append history\n",
        "        results_loss.append(epoch_loss)\n",
        "        results_metric.append(epoch_acc)\n",
        "        results_val_metric_Gita.append(val_metric_Gita)\n",
        "        results_val_metric_subject_Gita.append(val_metric_subject_Gita)\n",
        "        results_val_loss_Gita.append(val_loss_Gita.item())\n",
        "\n",
        "\n",
        "    print('')\n",
        "    print(f\"\\r validation Gita: {val_metric_Gita:.2f} % by Subject: {val_metric_subject_Gita:.2f}%  \")\n",
        "\n",
        "    #compute metrics\n",
        "    Sen_spe_subject_Gita=sensitivity_specificity_support(Y_val_tensor_bySubject_Gita.data.cpu(), prediction_val_bySubject_Gita.data.cpu(), average='binary')*100\n",
        "    val_f1_score_Gita = sklearn.metrics.f1_score(Y_val_tensor_bySubject_Gita.data.cpu(), prediction_val_bySubject_Gita.data.cpu())*100\n",
        "    val_MCC_Gita = sklearn.metrics.matthews_corrcoef(Y_val_tensor_bySubject_Gita.data.cpu(), prediction_val_bySubject_Gita.data.cpu())\n",
        "    val_fpr_Gita, val_tpr_Gita, _ = sklearn.metrics.roc_curve(Y_val_tensor_bySubject_Gita.data.cpu(), output_val_bySubjects_Gita.data.cpu())\n",
        "    val_AUC_Gita = sklearn.metrics.auc(val_fpr_Gita, val_tpr_Gita)\n",
        "\n",
        "    #Métricas para T-SNE\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        output_train_Original, train_CNN_Original = model(X_tensor_Original)\n",
        "        output_train_Augmented, train_CNN_Augmented = model(X_tensor_Augmented)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        output_test_NeuroV, output_CNN_NeuroV = model(X_test_tensor_NeuroV)\n",
        "        prediction_test_NeuroV = torch.max(output_test_NeuroV, 1)[1]\n",
        "\n",
        "    test_metric_NeuroV = sklearn.metrics.accuracy_score(Y_test_tensor_NeuroV.data.cpu(), prediction_test_NeuroV.data.cpu())*100\n",
        "\n",
        "    output_test_bySubjects_NeuroV, Y_test_tensor_bySubject_NeuroV, prediction_test_bySubject_NeuroV =soft_output_by_subject( output_test_NeuroV, Y_test_NeuroV, subject_group_test_NeuroV)\n",
        "    test_metric_subject_NeuroV = sklearn.metrics.accuracy_score(Y_test_tensor_bySubject_NeuroV.data.cpu(), prediction_test_bySubject_NeuroV.data.cpu())*100\n",
        "\n",
        "    results_loss_Epochs.append(results_loss)\n",
        "    results_metric_Epochs.append(results_metric)\n",
        "    results_val_metric_Gita_Epochs.append(results_val_metric_Gita)\n",
        "    results_val_loss_Gita_Epochs.append(results_val_loss_Gita)\n",
        "\n",
        "    val_windows_metrics_Gita.append(val_metric_Gita)\n",
        "    val_subject_metrics_Gita.append(val_metric_subject_Gita)\n",
        "    Subject_Sen_spe_Gita.append([Sen_spe_subject_Gita[0]*100, Sen_spe_subject_Gita[1]*100])\n",
        "    Subject_f1_score_Gita.append(val_f1_score_Gita)\n",
        "    Subject_MCC_Gita.append(val_MCC_Gita)\n",
        "    Subject_AUC_Gita.append(val_AUC_Gita)\n",
        "    Subject_fpr_Gita.append(val_fpr_Gita)\n",
        "    Subject_tpr_Gita.append(val_tpr_Gita)\n",
        "\n",
        "    #Para covarianza y divergencia\n",
        "    #flattern_output_CNN_Original.append(output_CNN_Original)\n",
        "    Y_Original_fold.append(y_label_train_Gita[train_index_Gita])\n",
        "\n",
        "    #flattern_output_CNN_Augmented.append(output_CNN_Augmented)\n",
        "    Y_Augmented_fold.append(aug_labels)\n",
        "\n",
        "\n",
        "    #Variables para T-SNE\n",
        "    flattern_train_CNN_Original.append(train_CNN_Original)\n",
        "    Y_train_Original_fold.append(Y_tensor_Original)\n",
        "    flattern_train_CNN_Augmented.append(train_CNN_Augmented)\n",
        "    Y_train_Augmented_fold.append(Y_tensor_Augmented)\n",
        "\n",
        "    test_windows_metrics_NeuroV.append(test_metric_NeuroV)\n",
        "    test_subject_metrics_NeuroV.append(test_metric_subject_NeuroV)\n",
        "\n",
        "    torch.save(model.state_dict(), '/content/drive/MyDrive/Memoria/mix_speed_spec/pitchSpec/CNN_Gita_pataka_fold_'+str(k)+'.pt')"
      ],
      "metadata": {
        "id": "tXXsM11gBpK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Métricas"
      ],
      "metadata": {
        "id": "y5I2jbnVBeqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Métricas\n",
        "print(f'Gita: Accuracy:    {np.mean(val_subject_metrics_Gita):.2f} ({np.std(val_subject_metrics_Gita):.2f})%')\n",
        "print(f\"\\r      Sensitivity: {np.mean(np.stack(Subject_Sen_spe_Gita,0),0)[0]:.2f} ({np.std(np.stack(Subject_Sen_spe_Gita,0),0)[0]:.2f})% \")\n",
        "print(f\"\\r      Specifity:   {np.mean(np.stack(Subject_Sen_spe_Gita,0),0)[1]:.2f} ({np.std(np.stack(Subject_Sen_spe_Gita,0),0)[1]:.2f})% \")\n",
        "print(f'\\r      f1_score:    {np.mean(Subject_f1_score_Gita):.2f} ({np.std(Subject_f1_score_Gita):.2f})%')\n",
        "print(f'\\r      MCC:         {np.mean(Subject_MCC_Gita):.2f} ({np.std(Subject_MCC_Gita):.2f})')\n",
        "print(f'\\r      AUC:         {np.mean(Subject_AUC_Gita):.2f} ({np.std(Subject_AUC_Gita):.2f})')\n"
      ],
      "metadata": {
        "id": "fJvrhg4KBNOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_loss_Epochs_mean=np.stack(results_loss_Epochs,0).mean(axis=0)\n",
        "results_loss_Epochs_std=np.stack(results_loss_Epochs,0).std(axis=0)\n",
        "\n",
        "results_val_loss_Gita_Epochs_mean=np.stack(results_val_loss_Gita_Epochs,0).mean(axis=0)\n",
        "results_val_loss_Gita_Epochs_std=np.stack(results_val_loss_Gita_Epochs,0).std(axis=0)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "ax.plot(range(epoch+1),results_loss_Epochs_mean, alpha=0.5, color='#888888', label='train', linewidth = 2.0)\n",
        "ax.fill_between(range(epoch+1), results_loss_Epochs_mean - results_loss_Epochs_std, results_loss_Epochs_mean + results_loss_Epochs_std, color='#888888', alpha=0.4)\n",
        "\n",
        "ax.plot(range(epoch+1),results_val_loss_Gita_Epochs_mean, alpha=0.5, color='blue', label='Validation Gita', linewidth = 2.0)\n",
        "ax.fill_between(range(epoch+1), results_val_loss_Gita_Epochs_mean - results_val_loss_Gita_Epochs_std, results_val_loss_Gita_Epochs_mean + results_val_loss_Gita_Epochs_std, color='blue', alpha=0.2)\n",
        "\n",
        "\n",
        "ax.set_ylim([0,1])\n",
        "ax.legend(loc='lower right')\n",
        "ax.set_ylabel(\"Loss\")\n",
        "ax.set_xlabel(\"Epoch\")\n",
        "plt.savefig(\"/content/drive/MyDrive/Memoria/mix_speed_spec/pitchSpec/Loss_Train_Validation_pataka.pdf\", dpi=150)\n",
        "\n",
        "results_metric_Epochs_mean=np.stack(results_metric_Epochs,0).mean(axis=0)\n",
        "results_metric_Epochs_std=np.stack(results_metric_Epochs,0).std(axis=0)\n",
        "\n",
        "results_val_metric_Gita_Epochs_mean=np.stack(results_val_metric_Gita_Epochs,0).mean(axis=0)\n",
        "results_val_metric_Gita_Epochs_std=np.stack(results_val_metric_Gita_Epochs,0).std(axis=0)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "ax.plot(range(epoch+1),results_metric_Epochs_mean, alpha=0.5, color='#888888', label='train', linewidth = 2.0)\n",
        "ax.fill_between(range(epoch+1), results_metric_Epochs_mean - results_metric_Epochs_std, results_metric_Epochs_mean + results_metric_Epochs_std, color='#888888', alpha=0.4)\n",
        "\n",
        "ax.plot(range(epoch+1),results_val_metric_Gita_Epochs_mean, alpha=0.5, color='blue', label='Validation Gita', linewidth = 2.0)\n",
        "ax.fill_between(range(epoch+1), results_val_metric_Gita_Epochs_mean - results_val_metric_Gita_Epochs_std, results_val_metric_Gita_Epochs_mean + results_val_metric_Gita_Epochs_std, color='blue', alpha=0.2)\n",
        "\n",
        "ax.set_ylim([30,100])\n",
        "ax.legend(loc='lower right')\n",
        "\n",
        "ax.set_ylabel(\"Accuracy (%)\")\n",
        "ax.set_xlabel(\"Epoch\")\n",
        "plt.savefig(\"/content/drive/MyDrive/Memoria/mix_speed_spec/pitchSpec/Accuracy_Train_Validation_pataka_prob_100.pdf\", dpi=150)"
      ],
      "metadata": {
        "id": "XG_oAyzjBhzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Gita: Accuracy by windows:, {np.mean(val_windows_metrics_Gita):.2f} ({np.std(val_windows_metrics_Gita):.2f})%,Accuracy by subject:{np.mean(val_subject_metrics_Gita):.2f} ({np.std(val_subject_metrics_Gita):.2f})')"
      ],
      "metadata": {
        "id": "lbwBtJmYsBVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_ROC_k_fold(fpr_k_folds,tpr_k_folds,auc_k_folds,folds, color):\n",
        "    mean_fpr = np.linspace(0, 1, 100)\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    ax.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")\n",
        "    tprs=[]\n",
        "    for k in range(folds):\n",
        "        #display = sklearn.metrics.RocCurveDisplay(fpr=fpr_k_folds[k], tpr=tpr_k_folds[k], roc_auc=auc_k_folds[k],\n",
        "        #                           estimator_name='ROC fold'+str(k))\n",
        "        #display.plot()\n",
        "\n",
        "        interp_tpr = np.interp(mean_fpr, fpr_k_folds[k], tpr_k_folds[k])\n",
        "        interp_tpr[0] = 0.0\n",
        "        tprs.append(interp_tpr)\n",
        "    mean_tpr = np.mean(tprs, axis=0)\n",
        "    mean_auc =np.mean(auc_k_folds)\n",
        "    std_auc = np.std(auc_k_folds)\n",
        "    ax.plot(\n",
        "        mean_fpr,\n",
        "        mean_tpr,\n",
        "        color=color,\n",
        "        label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
        "        lw=2,\n",
        "        alpha=0.8,\n",
        "    )\n",
        "\n",
        "    std_tpr = np.std(tprs, axis=0)\n",
        "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
        "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
        "    ax.fill_between(\n",
        "        mean_fpr,\n",
        "        tprs_lower,\n",
        "        tprs_upper,\n",
        "        color=color,\n",
        "        alpha=0.2,\n",
        "        label=r\"$\\pm$ 1 std. dev.\",\n",
        "    )\n",
        "\n",
        "    ax.set(\n",
        "        xlim=[-0.05, 1.05],\n",
        "        ylim=[-0.05, 1.05],\n",
        "        xlabel=\"False Positive Rate\",\n",
        "        ylabel=\"True Positive Rate\",\n",
        "       # title=f\"Mean ROC curve with variability\\n(Positive label '{target_names[1]}')\",\n",
        "    )\n",
        "    ax.axis(\"square\")\n",
        "    ax.legend(loc=\"lower right\")\n",
        "    plt.savefig(\"/content/drive/MyDrive/Memoria/mix_speed_spec/pitchSpec/ROC_Subject_fpr_Gita.pdf\", dpi=150)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "ysdyBYUDsNkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_ROC_k_fold(Subject_fpr_Gita,Subject_tpr_Gita,Subject_AUC_Gita, 10, 'blue')"
      ],
      "metadata": {
        "id": "Y6KpPTPUsOmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Métricas Cross-Validation (Neurovoz)"
      ],
      "metadata": {
        "id": "dLnF6t1w4c_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'NeuroV: Accuracy:  {np.mean(test_subject_metrics_NeuroV):.2f} ({np.std(test_subject_metrics_NeuroV):.2f})%')\n",
        "print(f'Test NeuroV: Accuracy by windows:, {np.mean(test_windows_metrics_NeuroV):.2f} ({np.std(test_windows_metrics_NeuroV):.2f})%,Accuracy by subject:{np.mean(test_subject_metrics_NeuroV):.2f} ({np.std(test_subject_metrics_NeuroV):.2f})')"
      ],
      "metadata": {
        "id": "5V_29M1L4gqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Divergencia y varianza"
      ],
      "metadata": {
        "id": "D2Ii23x4yTaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def KLdivergence(x, y):\n",
        "#  \"\"\"Compute the Kullback-Leibler divergence between two multivariate samples.\n",
        "#  Parameters\n",
        "#  ----------\n",
        "#  x : 2D array (n,d)\n",
        "#    Samples from distribution P, which typically represents the true\n",
        "#    distribution.\n",
        "#  y : 2D array (m,d)\n",
        "#    Samples from distribution Q, which typically represents the approximate\n",
        "#    distribution.\n",
        "#  Returns\n",
        "#  -------\n",
        "#  out : float\n",
        "#    The estimated Kullback-Leibler divergence D(P||Q).\n",
        "#  References\n",
        "#  ----------\n",
        "#  Pérez-Cruz, F. Kullback-Leibler divergence estimation of\n",
        "#continuous distributions IEEE International Symposium on Information\n",
        "#Theory, 2008.\n",
        "#  \"\"\"\n",
        "  from scipy.spatial import cKDTree as KDTree\n",
        "\n",
        "  # Check the dimensions are consistent\n",
        "  x = np.atleast_2d(x)\n",
        "  y = np.atleast_2d(y)\n",
        "\n",
        "  n,d = x.shape\n",
        "  m,dy = y.shape\n",
        "\n",
        "  assert(d == dy)\n",
        "\n",
        "\n",
        "  # Build a KD tree representation of the samples and find the nearest neighbour\n",
        "  # of each point in x.\n",
        "  xtree = KDTree(x)\n",
        "  ytree = KDTree(y)\n",
        "\n",
        "  # Get the first two nearest neighbours for x, since the closest one is the\n",
        "  # sample itself.\n",
        "  r = xtree.query(x, k=2, eps=.01, p=2)[0][:,1]\n",
        "  s = ytree.query(x, k=1, eps=.01, p=2)[0]\n",
        "\n",
        "  # There is a mistake in the paper. In Eq. 14, the right side misses a negative sign\n",
        "  # on the first term of the right hand side.\n",
        "  return -np.log(r/s).sum() * d / n + np.log(m / (n - 1.))"
      ],
      "metadata": {
        "id": "s5FC7TgVyWvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KL_HC_1=[]\n",
        "KL_PD_1=[]\n",
        "KL_HC_2=[]\n",
        "KL_PD_2=[]\n",
        "for k in range(10): #output por train, val por train\n",
        "    KL_HC_1.append(KLdivergence(flattern_train_CNN_Original[k].data.cpu()[np.where(Y_Original_fold[k]==0)], flattern_train_CNN_Augmented[k].data.cpu()[np.where(Y_Augmented_fold[k]==0)]))\n",
        "    KL_HC_2.append(KLdivergence(flattern_train_CNN_Augmented[k].data.cpu()[np.where(Y_Augmented_fold[k]==0)], flattern_train_CNN_Original[k].data.cpu()[np.where(Y_Original_fold[k]==0)]))\n",
        "\n",
        "    KL_PD_1.append(KLdivergence(flattern_train_CNN_Original[k].data.cpu()[np.where(Y_Original_fold[k]==1)], flattern_train_CNN_Augmented[k].data.cpu()[np.where(Y_Augmented_fold[k]==1)]))\n",
        "    KL_PD_2.append(KLdivergence(flattern_train_CNN_Augmented[k].data.cpu()[np.where(Y_Augmented_fold[k]==1)], flattern_train_CNN_Original[k].data.cpu()[np.where(Y_Original_fold[k]==1)]))\n",
        "\n",
        "\n",
        "\n",
        "print(f'KL para HC, {np.mean(KL_HC_1):.2f} ({np.std(KL_HC_1):.2f})')\n",
        "print(f'KL para HC, {np.mean(KL_HC_2):.2f} ({np.std(KL_HC_2):.2f})')\n",
        "\n",
        "print(f'KL para PD, {np.mean(KL_PD_1):.2f} ({np.std(KL_PD_1):.2f})')\n",
        "print(f'KL para PD, {np.mean(KL_PD_2):.2f} ({np.std(KL_PD_2):.2f})')\n",
        "print('')\n",
        "\n",
        "print(f'KL para HC, {np.mean([KL_HC_1, KL_HC_2]):.2f} ({np.std([KL_HC_1, KL_HC_2]):.2f})')\n",
        "print(f'KL para PD, {np.mean([KL_PD_1, KL_PD_2]):.2f} ({np.std([KL_PD_1, KL_PD_2]):.2f})')"
      ],
      "metadata": {
        "id": "1s7VGmbLzJIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Varianza"
      ],
      "metadata": {
        "id": "ZykW12ixzyzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Variance_HC, Variance_PD=[],[]\n",
        "for k in range(10): #output o val por train\n",
        "    Original_features_HC=flattern_train_CNN_Original[k].data.cpu()[np.where(Y_Original_fold[k]==0)]\n",
        "    Augmented_features_HC=flattern_train_CNN_Augmented[k].data.cpu()[np.where(Y_Augmented_fold[k]==0)]\n",
        "    Original_features_PD=flattern_train_CNN_Original[k].data.cpu()[np.where(Y_Original_fold[k]==1)]\n",
        "    Augmented_features_PD=flattern_train_CNN_Augmented[k].data.cpu()[np.where(Y_Augmented_fold[k]==1)]\n",
        "\n",
        "    features_HC=torch.concat([Original_features_HC, Augmented_features_HC])\n",
        "    features_PD=torch.concat([Original_features_PD, Augmented_features_PD])\n",
        "    Variance_HC.append(np.trace(np.cov(np.transpose(features_HC))))\n",
        "    Variance_PD.append(np.trace(np.cov(np.transpose(features_PD))))\n",
        "\n",
        "print(f'Cov para HC, {np.mean(Variance_HC):.2f} ({np.std(Variance_HC):.2f})')\n",
        "print(f'Cov para PD, {np.mean(Variance_PD):.2f} ({np.std(Variance_PD):.2f})')"
      ],
      "metadata": {
        "id": "cnwqQtuezyEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## T-SNE"
      ],
      "metadata": {
        "id": "UgIz-CjhgkSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_embedding(X, y, d, title=None):\n",
        "    \"\"\"Plot an embedding X with the class label y colored by the domain d.\"\"\"\n",
        "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
        "    X = (X - x_min) / (x_max - x_min)\n",
        "    # Plot colors numbers\n",
        "    plt.figure(figsize=(10,10))\n",
        "    ax = plt.subplot(111)\n",
        "    colores=[(0,0.6,1), (0,0,1), (1,0.5,0.5), (1,0,0)  ]\n",
        "\n",
        "    for i in range(X.shape[0]):\n",
        "        # plot colored number\n",
        "        #plt.text(X[i, 0], X[i, 1], 'o',\n",
        "        #         color=colores[y[i]],\n",
        "        #         fontdict={ 'size': 14})\n",
        "        plt.plot(X[i, 0], X[i, 1], 'o',\n",
        "                 color=colores[y[i]],#plt.cm.brw(y[i]),\n",
        "                  )\n",
        "\n",
        "    plt.xticks([]), plt.yticks([])\n",
        "    plt.legend(['Augmented_HC', 'Augmented_PD', 'Original_HC', 'Original_PD'] )\n",
        "    ax = plt.gca()\n",
        "    leg = ax.get_legend()\n",
        "    leg.legendHandles[0].set_color((0,0.6,1))\n",
        "    leg.legendHandles[1].set_color((0,0,1))\n",
        "    leg.legendHandles[2].set_color((1,0.5,0.5))\n",
        "    leg.legendHandles[3].set_color((1,0,0))\n",
        "    if title is not None:\n",
        "        plt.title(title)"
      ],
      "metadata": {
        "id": "qDnjGEkMeFX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_SNE= TSNE(n_components=2,n_iter=500,n_iter_without_progress=150, n_jobs=2, random_state=0)\n",
        "\n",
        "for k in range(10):\n",
        "    CCN_train=np.concatenate([flattern_train_CNN_Augmented[k].data.cpu(), flattern_train_CNN_Original[k].data.cpu()])\n",
        "    Y_train=np.concatenate([ Y_train_Augmented_fold[k].data.cpu(), Y_train_Original_fold[k].data.cpu()])\n",
        "    Y_train_plot=np.concatenate([Y_train_Augmented_fold[k].data.cpu(), Y_train_Original_fold[k].data.cpu()+2])\n",
        "    domain_train=np.concatenate([np.ones( Y_train_Augmented_fold[k].shape), np.zeros(Y_train_Original_fold[k].shape)])\n",
        "\n",
        "    projections=t_SNE.fit_transform(CCN_train,Y_train)\n",
        "\n",
        "    plot_embedding(projections,Y_train_plot,domain_train, 't-SNE embeedding')\n",
        "    plt.savefig(\"/content/drive/MyDrive/Memoria/mix_speed_spec/pitchSpec/T-SNE{}.pdf\".format(k), dpi=150)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "P1R3lRmXd_pi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}